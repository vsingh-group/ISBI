{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation for model training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1 = pd.read_csv('./PIB_all_July_10_2019.csv') #Load the whole dataset\n",
    "data_v2 = data_v1.copy()\n",
    "data_v3 = data_v1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing by visit version\n",
    "list_v1 = []\n",
    "for i in range(1,10):\n",
    "    list_v1.append('pdt0000'+str(i))\n",
    "for i in range(10,100):\n",
    "    list_v1.append('pdt000'+str(i))\n",
    "for i in range(100,260):\n",
    "    list_v1.append('pdt00'+str(i))\n",
    "    \n",
    "\n",
    "list_v2 = []\n",
    "for i in range(1,10):\n",
    "    list_v2.append('pdt0000'+str(i)+'_v2')\n",
    "for i in range(10,100):\n",
    "    list_v2.append('pdt000'+str(i)+'_v2')\n",
    "for i in range(100,260):\n",
    "    list_v2.append('pdt00'+str(i)+'_v2')\n",
    "list_v3 = []\n",
    "for i in range(1,10):\n",
    "    list_v3.append('pdt0000'+str(i)+'_v3')\n",
    "for i in range(10,100):\n",
    "    list_v3.append('pdt000'+str(i)+'_v3')\n",
    "for i in range(100,260):\n",
    "    list_v3.append('pdt00'+str(i)+'_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning, leaving subjects only present in all 3 visits\n",
    "delete_list_1 = []\n",
    "delete_list_2 = []\n",
    "delete_list_3 = []\n",
    "for i in range(0,data_v1.shape[0]):\n",
    "    if not(data_v1['subjectid'][i] in list_v1):\n",
    "        delete_list_1.append(i)\n",
    "    if not(data_v2['subjectid'][i] in list_v2):\n",
    "        delete_list_2.append(i)\n",
    "    if not(data_v3['subjectid'][i] in list_v3):\n",
    "        delete_list_3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.drop(delete_list_1 ,inplace=True)\n",
    "data_v2.drop(delete_list_2 ,inplace=True)\n",
    "data_v3.drop(delete_list_3 ,inplace=True)\n",
    "data_v1.reset_index(drop=True, inplace=True)\n",
    "data_v2.reset_index(drop=True, inplace=True)\n",
    "data_v3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_list = []\n",
    "list_v1 = data_v1['subjectid'].values.tolist()\n",
    "list_v2 = data_v2['subjectid'].values.tolist()\n",
    "list_v3 = data_v3['subjectid'].values.tolist()\n",
    "for i in range(0,data_v1.shape[0]):\n",
    "    if not(list_v1[i] + '_v2'in list_v2 and list_v1[i] + '_v3'in list_v3):\n",
    "        delete_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.drop(delete_list ,inplace=True)\n",
    "data_v1.reset_index(drop=True, inplace=True)\n",
    "list_v1 = data_v1['subjectid'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_v2 = []\n",
    "list_v3 = []\n",
    "for i in range(0,len(list_v1)):\n",
    "    list_v2.append(list_v1[i] + '_v2')\n",
    "    list_v3.append(list_v1[i] + '_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_list_2 = []\n",
    "delete_list_3 = []\n",
    "for i in range(0,data_v2.shape[0]):\n",
    "    if not(data_v2['subjectid'][i] in list_v2):\n",
    "        delete_list_2.append(i)\n",
    "for i in range(0,data_v3.shape[0]):\n",
    "    if not(data_v3['subjectid'][i] in list_v3):\n",
    "        delete_list_3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.drop(delete_list_2 ,inplace=True)\n",
    "data_v3.drop(delete_list_3 ,inplace=True)\n",
    "data_v2.reset_index(drop=True, inplace=True)\n",
    "data_v3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_amyloid = []\n",
    "for i in range(0,data_v3.shape[0]):\n",
    "    if data_v3['pib_index'][i] > 1.18:  # list of amyloid positive subjects after visit 3\n",
    "        list_amyloid.append(data_v1['subjectid'][i] + '_v3')\n",
    "        print(data_v1['subjectid'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store 3 lists into csv\n",
    "data_v2.to_csv(\"data_v2.csv\", index=False)\n",
    "data_v1.to_csv(\"data_v1.csv\", index=False)\n",
    "data_v3.to_csv(\"data_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_v1 = data_v1['subjectid'].values.tolist()#list of subjectid\n",
    "list_v2 = data_v2['subjectid'].values.tolist()\n",
    "list_v3 = data_v3['subjectid'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "for i in range(0,len(list_v1)):\n",
    "    l1.append(list_v1[i]+ \"_connectivity_matrix_manhattan.csv\")\n",
    "    l2.append(list_v1[i]+ \"_v2_connectivity_matrix_manhattan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filePath = './v1/'\n",
    "filelist = os.listdir(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean connectivity_matrix files in folder, leaving only the files related to slected subjects\n",
    "for i in range(0,len(filelist)):\n",
    "    if not(filelist[i] in l1):\n",
    "        if os.path.exists(filePath+ filelist[i]):\n",
    "            os.remove(filePath+ filelist[i])\n",
    "        else:\n",
    "            print ('no' + filePath+ filelist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparation for APOE group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv('./ALL_reggie_sex_apoe_age.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all = [] # list of all subject ids\n",
    "list_pos = [] # list of apoe+ subject ids\n",
    "list_neg = [] # list of apoe- subject ids\n",
    "lis_female = [] # list of female subject ids (for statistic purpose)\n",
    "lis_age = [] # list of all age information (for statistic purpose)\n",
    "for i in range(0,da.shape[0]):\n",
    "    if da['subjectid'][i] in list_v3:\n",
    "        if da['apoe_e1'][i] == 4 or da['apoe_e2'][i] == 4: # apoe+/- standard\n",
    "            list_pos.append(da['subjectid'][i])\n",
    "        else:\n",
    "            list_neg.append(da['subjectid'][i])\n",
    "        list_all.append(da['subjectid'][i])\n",
    "        lis_age.append(da['PIB_Age'][i])\n",
    "        if da['gender'][i] == 'Female':\n",
    "            lis_female.append( da['gender'][i])\n",
    "        #print(da['subjectid'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store apoe+ subject ids in txt file\n",
    "with open('APOE_POS.txt', 'w') as filehandle:\n",
    "    for listitem in list_pos:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(list_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(lis_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.std(lis_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(lis_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ages for all subject ids in txt file\n",
    "with open('age.txt', 'w') as filehandle:\n",
    "    for listitem in lis_age:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Amyloid_POS.txt', 'w') as filehandle:\n",
    "    for listitem in list_amyloid:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
